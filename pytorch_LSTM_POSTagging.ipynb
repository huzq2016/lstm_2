{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee54ca4",
   "metadata": {},
   "source": [
    "# tutorial \n",
    "- https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b2d6dc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x105a5e310>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519eb5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0187,  0.1713, -0.2944]],\n",
      "\n",
      "        [[-0.3521,  0.1026, -0.2971]],\n",
      "\n",
      "        [[-0.3191,  0.0781, -0.1957]],\n",
      "\n",
      "        [[-0.1634,  0.0941, -0.1637]],\n",
      "\n",
      "        [[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>)\n",
      "(tensor([[[-0.3368,  0.0959, -0.0538]]], grad_fn=<StackBackward0>), tensor([[[-0.9825,  0.4715, -0.0633]]], grad_fn=<StackBackward0>))\n"
     ]
    }
   ],
   "source": [
    "lstm = nn.LSTM(3, 3)  # Input dim is 3, output dim is 3\n",
    "inputs = [torch.randn(1, 3) for _ in range(5)]  # make a sequence of length 5\n",
    "\n",
    "# initialize the hidden state.\n",
    "hidden = (torch.randn(1, 1, 3),\n",
    "          torch.randn(1, 1, 3))\n",
    "for i in inputs:\n",
    "    # Step through the sequence one element at a time.\n",
    "    # after each step, hidden contains the hidden state.\n",
    "    out, hidden = lstm(i.view(1, 1, -1), hidden)\n",
    "\n",
    "# alternatively, we can do the entire sequence all at once.\n",
    "# the first value returned by LSTM is all of the hidden states throughout\n",
    "# the sequence. the second is just the most recent hidden state\n",
    "# (compare the last slice of \"out\" with \"hidden\" below, they are the same)\n",
    "# The reason for this is that:\n",
    "# \"out\" will give you access to all hidden states in the sequence\n",
    "# \"hidden\" will allow you to continue the sequence and backpropagate,\n",
    "# by passing it as an argument  to the lstm at a later time\n",
    "# Add the extra 2nd dimension\n",
    "inputs = torch.cat(inputs).view(len(inputs), 1, -1)\n",
    "hidden = (torch.randn(1, 1, 3), torch.randn(1, 1, 3))  # clean out hidden state\n",
    "out, hidden = lstm(inputs, hidden)\n",
    "print(out)\n",
    "print(hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d4bd55",
   "metadata": {},
   "source": [
    "# Example: An LSTM for Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77ab0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'The': 0, 'dog': 1, 'ate': 2, 'the': 3, 'apple': 4, 'Everybody': 5, 'read': 6, 'that': 7, 'book': 8}\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequence(seq, to_ix):\n",
    "    idxs = [to_ix[w] for w in seq]\n",
    "    return torch.tensor(idxs, dtype=torch.long)\n",
    "\n",
    "\n",
    "training_data = [\n",
    "    # Tags are: DET - determiner; NN - noun; V - verb\n",
    "    # For example, the word \"The\" is a determiner\n",
    "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
    "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"])\n",
    "]\n",
    "word_to_ix = {}\n",
    "# For each words-list (sentence) and tags-list in each tuple of training_data\n",
    "for sent, tags in training_data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:  # word has not been assigned an index yet\n",
    "            word_to_ix[word] = len(word_to_ix)  # Assign each word with a unique index\n",
    "print(word_to_ix)\n",
    "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2}  # Assign each tag with a unique index\n",
    "\n",
    "# These will usually be more like 32 or 64 dimensional.\n",
    "# We will keep them small, so we can see how the weights change as we train.\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c9cad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # The LSTM takes word embeddings as inputs, and outputs hidden states\n",
    "        # with dimensionality hidden_dim.\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "\n",
    "        # The linear layer that maps from hidden state space to tag space\n",
    "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
    "\n",
    "    def forward(self, sentence):\n",
    "        embeds = self.word_embeddings(sentence)\n",
    "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
    "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
    "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "701e2467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1389, -1.2024, -0.9693],\n",
      "        [-1.1065, -1.2200, -0.9834],\n",
      "        [-1.1286, -1.2093, -0.9726],\n",
      "        [-1.1190, -1.1960, -0.9916],\n",
      "        [-1.0137, -1.2642, -1.0366]])\n",
      "tensor([[-0.0462, -4.0106, -3.6096],\n",
      "        [-4.8205, -0.0286, -3.9045],\n",
      "        [-3.7876, -4.1355, -0.0394],\n",
      "        [-0.0185, -4.7874, -4.6013],\n",
      "        [-5.7881, -0.0186, -4.1778]])\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(EMBEDDING_DIM, HIDDEN_DIM, len(word_to_ix), len(tag_to_ix))\n",
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# See what the scores are before training\n",
    "# Note that element i,j of the output is the score for tag j for word i.\n",
    "# Here we don't need to train, so the code is wrapped in torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "    print(tag_scores)\n",
    "\n",
    "for epoch in range(300):  # again, normally you would NOT do 300 epochs, it is toy data\n",
    "    for sentence, tags in training_data:\n",
    "        # Step 1. Remember that Pytorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Get our inputs ready for the network, that is, turn them into\n",
    "        # Tensors of word indices.\n",
    "        sentence_in = prepare_sequence(sentence, word_to_ix)\n",
    "        targets = prepare_sequence(tags, tag_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        tag_scores = model(sentence_in)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        #  calling optimizer.step()\n",
    "        loss = loss_function(tag_scores, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# See what the scores are after training\n",
    "with torch.no_grad():\n",
    "    inputs = prepare_sequence(training_data[0][0], word_to_ix)\n",
    "    tag_scores = model(inputs)\n",
    "\n",
    "    # The sentence is \"the dog ate the apple\".  i,j corresponds to score for tag j\n",
    "    # for word i. The predicted tag is the maximum scoring tag.\n",
    "    # Here, we can see the predicted sequence below is 0 1 2 0 1\n",
    "    # since 0 is index of the maximum value of row 1,\n",
    "    # 1 is the index of maximum value of row 2, etc.\n",
    "    # Which is DET NOUN VERB DET NOUN, the correct sequence!\n",
    "    print(tag_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bf7a7a",
   "metadata": {},
   "source": [
    "# check parameters of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d507878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method parameters in module torch.nn.modules.module:\n",
      "\n",
      "parameters(recurse: bool = True) -> Iterator[torch.nn.parameter.Parameter] method of __main__.LSTMTagger instance\n",
      "    Returns an iterator over module parameters.\n",
      "    \n",
      "    This is typically passed to an optimizer.\n",
      "    \n",
      "    Args:\n",
      "        recurse (bool): if True, then yields parameters of this module\n",
      "            and all submodules. Otherwise, yields only parameters that\n",
      "            are direct members of this module.\n",
      "    \n",
      "    Yields:\n",
      "        Parameter: module parameter\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> # xdoctest: +SKIP(\"undefined vars\")\n",
      "        >>> for param in model.parameters():\n",
      "        >>>     print(type(param), param.size())\n",
      "        <class 'torch.Tensor'> (20L,)\n",
      "        <class 'torch.Tensor'> (20L, 1L, 5L, 5L)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c29d3c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 7.3412e-01,  8.0615e-04, -3.3758e-01,  6.2446e-01,  2.0486e-01,\n",
      "         -1.0973e+00],\n",
      "        [-9.2287e-01, -7.1421e-01,  9.6096e-01, -1.2692e+00, -1.8903e-01,\n",
      "         -6.0069e-01],\n",
      "        [ 6.4489e-01, -6.8376e-01,  2.1375e+00,  6.7106e-01,  3.9116e-01,\n",
      "         -7.5065e-01],\n",
      "        [ 4.5504e-01,  1.3352e+00, -9.5383e-01, -1.2280e+00,  3.4942e+00,\n",
      "         -2.5017e+00],\n",
      "        [-4.8974e-01, -5.7369e-02,  9.1785e-01, -1.1828e+00,  9.0761e-01,\n",
      "          3.0940e-01],\n",
      "        [ 1.4131e+00,  1.7109e+00,  1.4875e-01, -2.6694e+00,  2.0926e-01,\n",
      "          2.0688e-01],\n",
      "        [-9.3109e-02,  1.4724e-01,  1.4168e+00,  1.2175e+00,  1.1629e+00,\n",
      "          9.5881e-01],\n",
      "        [-6.4901e-01,  1.5777e+00,  1.4035e-01,  2.0601e+00, -3.1149e-01,\n",
      "         -8.6065e-01],\n",
      "        [-1.0945e+00,  1.2314e+00,  1.4436e+00, -7.7375e-01,  2.1218e-01,\n",
      "         -5.7816e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3364, -0.2644,  0.5200, -0.1999,  0.1337,  0.1206],\n",
      "        [ 0.2313,  0.4014,  0.0784, -0.4507,  0.4148, -0.1503],\n",
      "        [-0.1040,  0.2709, -0.2011,  0.2668,  0.3113, -0.4389],\n",
      "        [-0.2925,  0.2310,  0.6325, -0.2331,  0.1878, -0.2300],\n",
      "        [-0.2940, -0.1755,  0.0464,  0.8749,  0.7024, -0.4075],\n",
      "        [ 0.0141,  0.2056,  0.1105, -0.2406,  0.2702,  0.2364],\n",
      "        [-0.0160, -0.0782,  0.4019,  0.3454, -0.2859,  0.3705],\n",
      "        [ 0.0946, -0.2950,  0.2709, -0.3393,  0.4064, -0.2546],\n",
      "        [ 0.1412,  0.0435,  0.1473,  0.3513, -0.2071, -0.0910],\n",
      "        [-0.1114, -0.0147, -0.8330,  0.1437, -0.2322,  0.0380],\n",
      "        [ 0.4062, -0.0553, -0.0710, -0.3675, -0.3905,  0.4146],\n",
      "        [-0.0845,  0.0916,  0.0413, -0.2563,  0.2468,  0.2312],\n",
      "        [ 0.1812, -0.4436,  0.3060,  0.1076, -0.1205,  0.1842],\n",
      "        [-0.1471, -0.0486,  0.3459, -0.5566,  0.0120, -0.0893],\n",
      "        [-0.1908,  0.4973, -0.4498,  0.5447,  0.1542, -0.5965],\n",
      "        [-0.7067,  0.0490,  0.2308, -1.3140, -0.4913,  0.2811],\n",
      "        [ 0.1987,  0.5555, -1.0479,  0.0495, -0.3170, -0.7302],\n",
      "        [ 0.1992, -0.1929, -0.3379,  0.2171, -0.3395, -0.0627],\n",
      "        [ 0.2343,  0.1946,  0.5590, -0.2812,  0.0717, -0.2231],\n",
      "        [-0.2515, -0.1572,  0.4277, -0.2381, -0.3462, -0.1088],\n",
      "        [-0.2689,  0.5677,  0.0856,  0.0673,  0.0765, -0.3874],\n",
      "        [-0.2142,  0.3293,  0.6204, -0.1990,  0.2855, -0.5165],\n",
      "        [ 0.3972,  0.4098,  0.5828,  0.4557,  0.4995, -0.2118],\n",
      "        [-0.2353, -0.3710,  0.3479, -0.1197,  0.2065,  0.0533]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3680, -0.1415,  0.1020, -0.0509, -0.3959,  0.0942],\n",
      "        [ 0.0173, -0.1216,  0.1815,  0.0390, -0.1121,  0.3546],\n",
      "        [ 0.2125,  0.0775, -0.1004, -0.3581,  0.2778, -0.1361],\n",
      "        [-0.2664,  0.3283,  0.1610,  0.0331, -0.0131, -0.2034],\n",
      "        [ 0.0782,  0.3984, -0.0117, -0.1091,  0.3266, -0.0590],\n",
      "        [ 0.3203,  0.1062,  0.3705,  0.2330, -0.1945,  0.2801],\n",
      "        [ 0.0049, -0.3314, -0.0763, -0.3706, -0.2038, -0.2864],\n",
      "        [ 0.2770, -0.0799, -0.0676,  0.1971,  0.1811, -0.2751],\n",
      "        [ 0.1380,  0.1718, -0.3257,  0.4010, -0.2317, -0.1503],\n",
      "        [-0.2918,  0.3333,  0.0121,  0.3781, -0.1406,  0.2728],\n",
      "        [-0.1419, -0.3354,  0.0899,  0.0043,  0.0189, -0.1787],\n",
      "        [ 0.0053,  0.1201,  0.1501, -0.3272,  0.2041,  0.0380],\n",
      "        [ 0.2569,  0.3326, -0.4210,  0.6706, -0.3992,  0.2643],\n",
      "        [ 0.0253,  0.1997, -0.1833,  0.2104, -0.1254, -0.3620],\n",
      "        [ 0.1728,  0.2093,  0.4008, -0.1416,  0.3157,  0.2562],\n",
      "        [-0.2276, -0.3730,  0.3692, -0.4409,  0.3196, -0.3463],\n",
      "        [ 0.2844,  0.0467,  0.0249, -0.1217, -0.3591, -0.1174],\n",
      "        [ 0.0069, -0.2454, -0.1152, -0.1550,  0.3600,  0.3579],\n",
      "        [ 0.3520,  0.3652, -0.3770,  0.1604,  0.1690, -0.3327],\n",
      "        [ 0.1358, -0.2161,  0.1045,  0.1130,  0.4359, -0.2361],\n",
      "        [-0.3076,  0.4322,  0.1277,  0.2215,  0.0858, -0.1944],\n",
      "        [ 0.2433, -0.2821,  0.0635,  0.0787,  0.3041, -0.3056],\n",
      "        [-0.2739,  0.2123, -0.3757, -0.2666, -0.4167, -0.2459],\n",
      "        [-0.0914, -0.2353, -0.1606, -0.3474,  0.2857, -0.1008]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0119,  0.2557, -0.0880,  1.0510,  0.7543, -0.3364, -0.3194, -0.2342,\n",
      "        -0.2448, -0.4023, -0.4747, -0.2799,  0.2954, -0.0362, -0.0925, -0.4505,\n",
      "         0.2353, -0.0896, -0.0180, -0.0342,  0.3776,  1.0622,  0.5899,  0.2005],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1834, -0.1666,  0.4772,  0.7618,  0.2482,  0.4168,  0.2287, -0.2858,\n",
      "        -0.2277, -0.5922, -0.3066,  0.2134, -0.1823,  0.4769, -0.0988,  0.1282,\n",
      "         0.0837, -0.2980,  0.4124, -0.0957,  0.0748,  1.0000,  0.7326, -0.0957],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.2423, -0.8033,  0.7121, -1.9272,  1.9857,  0.3270],\n",
      "        [-0.6271,  0.5174, -0.4203,  2.7802, -0.0774, -0.3802],\n",
      "        [ 1.0373, -0.0333, -1.0692, -1.5291, -2.0368, -0.2753]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0198,  0.4493, -0.3634], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for parameter in model.parameters():\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9953b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'> torch.Size([9, 6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([24, 6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([24, 6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([24])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([24])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3, 6])\n",
      "<class 'torch.nn.parameter.Parameter'> torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(type(param), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c34b1280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prettytable\n",
      "  Downloading prettytable-3.7.0-py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from prettytable) (0.2.6)\n",
      "Installing collected packages: prettytable\n",
      "Successfully installed prettytable-3.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b02772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+-------------------+\n",
      "|        Mod name        | Parameters Listed |\n",
      "+------------------------+-------------------+\n",
      "| word_embeddings.weight |         54        |\n",
      "|   lstm.weight_ih_l0    |        144        |\n",
      "|   lstm.weight_hh_l0    |        144        |\n",
      "|    lstm.bias_ih_l0     |         24        |\n",
      "|    lstm.bias_hh_l0     |         24        |\n",
      "|   hidden2tag.weight    |         18        |\n",
      "|    hidden2tag.bias     |         3         |\n",
      "+------------------------+-------------------+\n",
      "Sum of trained paramters: 411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Mod name\", \"Parameters Listed\"])\n",
    "    t_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: \n",
    "            continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        t_params += param\n",
    "    print(table)\n",
    "    print(f\"Sum of trained paramters: {t_params}\")\n",
    "    return t_params\n",
    "\n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8761452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMTagger(\n",
      "  (word_embeddings): Embedding(9, 6)\n",
      "  (lstm): LSTM(6, 6)\n",
      "  (hidden2tag): Linear(in_features=6, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ebaa7e",
   "metadata": {},
   "source": [
    "## empty-parameter model (not working)\n",
    "- https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46feb9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Model(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(model, self).__init__()\n",
    "\n",
    "# model = Model()\n",
    "\n",
    "# for parameter in model.parameters():\n",
    "#     print(parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
